{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNcoWnoAaDWjDKebLv9t0P+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HFooladi/GNNs-For-Chemists/blob/main/notebooks/04_GNN_GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Convolutional Networks (GCN) Tutorial for Chemists and Pharmacists\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Graph Convolutional Networks (GCNs) are a powerful class of neural networks designed to work directly on graph-structured data. In chemistry and drug discovery, molecules are naturally represented as graphs, with atoms as nodes and bonds as edges, making GCNs particularly valuable for tasks like molecular property prediction and drug design.\n",
        "\n",
        "This notebook provides a step-by-step exploration of GCNs with a focus on:\n",
        "1. How different pooling methods (max, sum, mean) affect results\n",
        "2. The impact of network depth (increasing the number of layers)\n",
        "3. The effect of adding skip connections to the architecture"
      ],
      "metadata": {
        "id": "YxtQeGH8EV9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Requirements\n",
        "\n",
        "First, let's install the necessary packages:"
      ],
      "metadata": {
        "id": "Qzf1O_zmEbFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Intstall necessary libraries\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-\n",
        "{TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install -q rdkit\n",
        "!pip install -q networkx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv12bZ74EW4-",
        "outputId": "716d3d24-13aa-420b-db49-6999f6e2c4e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0+cu124\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_add_pool, global_max_pool, global_mean_pool\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import MoleculeNet\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, AllChem\n",
        "from rdkit.Chem.Draw import rdMolDraw2D\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import io\n",
        "from PIL import Image\n",
        "import random\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "CBrxhtgZEgTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Understanding Molecular Graphs\n",
        "\n",
        "Let's start by visualizing molecules as graphs, which is essential for understanding how GCNs process molecular data."
      ],
      "metadata": {
        "id": "QtZeuY3yEv_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mol_to_graph(smiles):\n",
        "    \"\"\"Convert a SMILES string to a PyTorch Geometric Data object\"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Get node features (atomic numbers as initial features)\n",
        "    node_features = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        features = [\n",
        "            atom.GetAtomicNum(),\n",
        "            atom.GetFormalCharge(),\n",
        "            atom.GetNumExplicitHs(),\n",
        "            atom.GetNumImplicitHs(),\n",
        "            int(atom.GetIsAromatic()),\n",
        "            atom.GetDegree()\n",
        "        ]\n",
        "        node_features.append(features)\n",
        "\n",
        "    x = torch.tensor(node_features, dtype=torch.float)\n",
        "\n",
        "    # Get edge indices\n",
        "    edge_indices = []\n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        # Add edges in both directions\n",
        "        edge_indices.append([i, j])\n",
        "        edge_indices.append([j, i])\n",
        "\n",
        "    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    # Get edge features (bond types)\n",
        "    edge_features = []\n",
        "    for bond in mol.GetBonds():\n",
        "        # Add features for both directions\n",
        "        features = [bond.GetBondTypeAsDouble()]\n",
        "        edge_features.append(features)\n",
        "        edge_features.append(features)\n",
        "\n",
        "    edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
        "\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, smiles=smiles)\n",
        "\n",
        "def visualize_molecule(smiles, title=\"Molecule\"):\n",
        "    \"\"\"Visualize a molecule using RDKit\"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    AllChem.Compute2DCoords(mol)\n",
        "\n",
        "    # Draw molecule\n",
        "    fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    drawer = rdMolDraw2D.MolDraw2DCairo(500, 500)\n",
        "    drawer.DrawMolecule(mol)\n",
        "    drawer.FinishDrawing()\n",
        "    img = drawer.GetDrawingText()\n",
        "\n",
        "    # Convert the image data to a PIL Image\n",
        "    pil_image = Image.open(io.BytesIO(img))\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(pil_image)\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def visualize_molecular_graph(smiles, title=\"Molecular Graph\"):\n",
        "    \"\"\"Visualize a molecule as a graph using NetworkX\"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    AllChem.Compute2DCoords(mol)\n",
        "\n",
        "    data = mol_to_graph(smiles)\n",
        "    G = to_networkx(data, to_undirected=True)\n",
        "\n",
        "    # Get the 2D coordinates from RDKit\n",
        "    pos = {}\n",
        "    for i, atom in enumerate(mol.GetAtoms()):\n",
        "        pos[i] = mol.GetConformer().GetAtomPosition(i)\n",
        "        pos[i] = (pos[i].x, -pos[i].y)  # Flip y for better visualization\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "\n",
        "    # Get atom labels\n",
        "    atom_labels = {i: atom.GetSymbol() for i, atom in enumerate(mol.GetAtoms())}\n",
        "\n",
        "    # Get atom features for node coloring\n",
        "    atom_features = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
        "\n",
        "    # Draw the graph\n",
        "    nx.draw(G, pos,\n",
        "            labels=atom_labels,\n",
        "            with_labels=True,\n",
        "            node_color=atom_features,\n",
        "            cmap=plt.cm.viridis,\n",
        "            node_size=500,\n",
        "            font_size=10,\n",
        "            font_color='white',\n",
        "            edge_color='gray')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example molecules\n",
        "example_molecules = {\n",
        "    \"Aspirin\": \"CC(=O)OC1=CC=CC=C1C(=O)O\",\n",
        "    \"Paracetamol\": \"CC(=O)NC1=CC=C(C=C1)O\",\n",
        "    \"Ibuprofen\": \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\"\n",
        "}\n",
        "\n",
        "# Visualize each molecule\n",
        "for name, smiles in example_molecules.items():\n",
        "    print(f\"\\n{name}\")\n",
        "    visualize_molecule(smiles, f\"{name} Structure\")\n",
        "    visualize_molecular_graph(smiles, f\"{name} as Graph\")"
      ],
      "metadata": {
        "id": "c8TTL91rEwUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Graph Convolutional Networks: Basic Concepts\n",
        "\n",
        "Now that we understand how molecules are represented as graphs, let's explore the basic concepts of Graph Convolutional Networks."
      ],
      "metadata": {
        "id": "76kVLBBsE2nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple visualization of GCN message passing\n",
        "def visualize_gcn_message_passing():\n",
        "    \"\"\"Create a visual explanation of GCN message passing\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Create a simple molecular graph for illustration\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(range(7))\n",
        "\n",
        "    # Define edges for a simple molecule (like benzene with a side chain)\n",
        "    edges = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 0), (1, 6)]\n",
        "    G.add_edges_from(edges)\n",
        "\n",
        "    # Define positions\n",
        "    pos = {\n",
        "        0: (0, 1),\n",
        "        1: (1, 0.5),\n",
        "        2: (1, -0.5),\n",
        "        3: (0, -1),\n",
        "        4: (-1, -0.5),\n",
        "        5: (-1, 0.5),\n",
        "        6: (2, 1)\n",
        "    }\n",
        "\n",
        "    # Initial state - just the graph\n",
        "    ax = axes[0]\n",
        "    nx.draw(G, pos,\n",
        "            node_color='lightblue',\n",
        "            node_size=500,\n",
        "            with_labels=True,\n",
        "            font_size=12,\n",
        "            font_color='black',\n",
        "            ax=ax)\n",
        "    ax.set_title(\"Initial Graph\")\n",
        "\n",
        "    # First GCN layer - gather information from neighbors\n",
        "    ax = axes[1]\n",
        "    nx.draw(G, pos,\n",
        "            node_color='lightblue',\n",
        "            node_size=500,\n",
        "            with_labels=True,\n",
        "            font_size=12,\n",
        "            font_color='black',\n",
        "            ax=ax)\n",
        "\n",
        "    # Add arrows to show information flow\n",
        "    central_node = 1\n",
        "    for neighbor in [0, 2, 6]:\n",
        "        ax.annotate(\"\",\n",
        "                  xy=pos[central_node],\n",
        "                  xytext=pos[neighbor],\n",
        "                  arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2))\n",
        "\n",
        "    ax.set_title(\"GCN Layer 1: Neighborhood Aggregation\")\n",
        "\n",
        "    # Second GCN layer - expanded neighborhood\n",
        "    ax = axes[2]\n",
        "    nx.draw(G, pos,\n",
        "            node_color='lightblue',\n",
        "            node_size=500,\n",
        "            with_labels=True,\n",
        "            font_size=12,\n",
        "            font_color='black',\n",
        "            ax=ax)\n",
        "\n",
        "    # Draw circles to show the receptive field\n",
        "    circle1 = plt.Circle(pos[central_node], 0.3, color='red', fill=False, linestyle='-', linewidth=2)\n",
        "    circle2 = plt.Circle(pos[central_node], 0.8, color='green', fill=False, linestyle='--', linewidth=2)\n",
        "    ax.add_patch(circle1)\n",
        "    ax.add_patch(circle2)\n",
        "\n",
        "    # Add a legend\n",
        "    ax.plot([], [], color='red', linestyle='-', linewidth=2, label='Layer 1 receptive field')\n",
        "    ax.plot([], [], color='green', linestyle='--', linewidth=2, label='Layer 2 receptive field')\n",
        "    ax.legend(loc='upper right')\n",
        "\n",
        "    ax.set_title(\"GCN Layer 2: Expanded Receptive Field\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_gcn_message_passing()"
      ],
      "metadata": {
        "id": "nNrWMQqNEz_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Implementing a Basic GCN\n",
        "\n",
        "Let's implement a basic GCN for molecular property prediction:"
      ],
      "metadata": {
        "id": "TimJSOp3E7I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicGCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2):\n",
        "        super(BasicGCN, self).__init__()\n",
        "\n",
        "        # Input layer\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "\n",
        "        # Hidden layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
        "\n",
        "        # Output layer\n",
        "        self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # First GCN layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Additional GCN layers\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "\n",
        "        # Global pooling (default: mean)\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        # MLP for final prediction\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Create a simple model to demonstrate\n",
        "sample_data = mol_to_graph(example_molecules[\"Aspirin\"])\n",
        "print(f\"Node features: {sample_data.x.shape}\")\n",
        "model = BasicGCN(sample_data.x.shape[1], 64, 1)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "7Sbx2-aCE_pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Exploring Different Pooling Methods\n",
        "\n",
        "Now let's compare the effect of different pooling methods: max, sum, and mean pooling."
      ],
      "metadata": {
        "id": "2cmBKyRuFA08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNWithPooling(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, pooling_method='mean'):\n",
        "        super(GCNWithPooling, self).__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "        # Set pooling method\n",
        "        self.pooling_method = pooling_method\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # GCN layers\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        # Apply the specified pooling method\n",
        "        if self.pooling_method == 'max':\n",
        "            x = global_max_pool(x, batch)\n",
        "        elif self.pooling_method == 'sum':\n",
        "            x = global_add_pool(x, batch)\n",
        "        else:  # Default to mean\n",
        "            x = global_mean_pool(x, batch)\n",
        "\n",
        "        # Final MLP\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def visualize_pooling_operations():\n",
        "    \"\"\"Visualize how different pooling operations work on node features\"\"\"\n",
        "    # Create a simple example\n",
        "    node_features = torch.tensor([\n",
        "        [1.0, 0.2],\n",
        "        [0.8, 0.4],\n",
        "        [0.3, 0.9],\n",
        "        [0.5, 0.6],\n",
        "        [0.2, 0.8],\n",
        "        [0.7, 0.3]\n",
        "    ], dtype=torch.float)\n",
        "\n",
        "    # Batch indicator: first 3 nodes belong to graph 0, next 3 to graph 1\n",
        "    batch = torch.tensor([0, 0, 0, 1, 1, 1], dtype=torch.long)\n",
        "\n",
        "    # Apply different pooling operations\n",
        "    mean_pooled = global_mean_pool(node_features, batch)\n",
        "    max_pooled = global_max_pool(node_features, batch)\n",
        "    sum_pooled = global_add_pool(node_features, batch)\n",
        "\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    # Original node features\n",
        "    ax = axes[0, 0]\n",
        "    ax.imshow(node_features.numpy(), cmap='viridis')\n",
        "    ax.set_title(\"Original Node Features\")\n",
        "    ax.set_xlabel(\"Feature Dimension\")\n",
        "    ax.set_ylabel(\"Node ID\")\n",
        "\n",
        "    for i in range(len(node_features)):\n",
        "        graph_id = batch[i].item()\n",
        "        for j in range(node_features.size(1)):\n",
        "            ax.text(j, i, f\"{node_features[i, j]:.1f}\",\n",
        "                   ha=\"center\", va=\"center\", color=\"white\")\n",
        "\n",
        "    # Add dividing line between graphs\n",
        "    ax.axhline(y=2.5, color='red', linestyle='-', linewidth=2)\n",
        "    ax.text(node_features.size(1) - 0.5, 1, \"Graph 0\", ha=\"right\", va=\"center\", color=\"white\", fontsize=12)\n",
        "    ax.text(node_features.size(1) - 0.5, 4, \"Graph 1\", ha=\"right\", va=\"center\", color=\"white\", fontsize=12)\n",
        "\n",
        "    # Mean pooling\n",
        "    ax = axes[0, 1]\n",
        "    ax.imshow(mean_pooled.numpy(), cmap='viridis')\n",
        "    ax.set_title(\"After Mean Pooling\")\n",
        "    ax.set_xlabel(\"Feature Dimension\")\n",
        "    ax.set_ylabel(\"Graph ID\")\n",
        "\n",
        "    for i in range(mean_pooled.size(0)):\n",
        "        for j in range(mean_pooled.size(1)):\n",
        "            ax.text(j, i, f\"{mean_pooled[i, j]:.2f}\",\n",
        "                   ha=\"center\", va=\"center\", color=\"white\")\n",
        "\n",
        "    # Max pooling\n",
        "    ax = axes[1, 0]\n",
        "    ax.imshow(max_pooled.numpy(), cmap='viridis')\n",
        "    ax.set_title(\"After Max Pooling\")\n",
        "    ax.set_xlabel(\"Feature Dimension\")\n",
        "    ax.set_ylabel(\"Graph ID\")\n",
        "\n",
        "    for i in range(max_pooled.size(0)):\n",
        "        for j in range(max_pooled.size(1)):\n",
        "            ax.text(j, i, f\"{max_pooled[i, j]:.2f}\",\n",
        "                   ha=\"center\", va=\"center\", color=\"white\")\n",
        "\n",
        "    # Sum pooling\n",
        "    ax = axes[1, 1]\n",
        "    ax.imshow(sum_pooled.numpy(), cmap='viridis')\n",
        "    ax.set_title(\"After Sum Pooling\")\n",
        "    ax.set_xlabel(\"Feature Dimension\")\n",
        "    ax.set_ylabel(\"Graph ID\")\n",
        "\n",
        "    for i in range(sum_pooled.size(0)):\n",
        "        for j in range(sum_pooled.size(1)):\n",
        "            ax.text(j, i, f\"{sum_pooled[i, j]:.2f}\",\n",
        "                   ha=\"center\", va=\"center\", color=\"white\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize how the different pooling operations work\n",
        "visualize_pooling_operations()"
      ],
      "metadata": {
        "id": "_du1U0n2FDKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Demonstrating the Differences Between Pooling Methods on Real Molecules\n",
        "\n",
        "Let's understand how different pooling methods impact results for molecular property prediction:"
      ],
      "metadata": {
        "id": "TJfJj0xoFIuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a dataset from MoleculeNet\n",
        "print(\"Loading ESOL dataset (water solubility data)...\")\n",
        "dataset = MoleculeNet(root='data', name='ESOL')\n",
        "print(f\"Dataset loaded: {len(dataset)} molecules\")\n",
        "\n",
        "# Split the dataset\n",
        "torch.manual_seed(42)\n",
        "indices = torch.randperm(len(dataset))\n",
        "train_idx = indices[:int(0.8 * len(dataset))]\n",
        "val_idx = indices[int(0.8 * len(dataset)):int(0.9 * len(dataset))]\n",
        "test_idx = indices[int(0.9 * len(dataset)):]\n",
        "\n",
        "train_dataset = dataset[train_idx]\n",
        "val_dataset = dataset[val_idx]\n",
        "test_dataset = dataset[test_idx]\n",
        "\n",
        "print(f\"Train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "# Create data loaders\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Function to train and evaluate models\n",
        "def train_and_evaluate(model, optimizer, criterion, train_loader, val_loader, test_loader, epochs=50, early_stopping=True):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 5\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data.x, data.edge_index, data.batch)\n",
        "            loss = criterion(out, data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * data.num_graphs\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data in val_loader:\n",
        "                data = data.to(device)\n",
        "                out = model(data.x, data.edge_index, data.batch)\n",
        "                loss = criterion(out, data.y)\n",
        "                val_loss += loss.item() * data.num_graphs\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Print progress\n",
        "        if epoch % 5 == 0:\n",
        "            print(f\"Epoch {epoch:3d}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
        "\n",
        "        # Check for early stopping\n",
        "        if early_stopping:\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                # Save the best model\n",
        "                torch.save(model.state_dict(), 'best_model.pt')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    # Load the best model if using early stopping\n",
        "    if early_stopping:\n",
        "        model.load_state_dict(torch.load('best_model.pt'))\n",
        "\n",
        "    # Evaluate on test set\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_preds = []\n",
        "    test_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data.x, data.edge_index, data.batch)\n",
        "            loss = criterion(out, data.y)\n",
        "            test_loss += loss.item() * data.num_graphs\n",
        "            test_preds.append(out.cpu())\n",
        "            test_targets.append(data.y.cpu())\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_preds = torch.cat(test_preds, dim=0)\n",
        "    test_targets = torch.cat(test_targets, dim=0)\n",
        "\n",
        "    return {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'test_loss': test_loss,\n",
        "        'test_preds': test_preds,\n",
        "        'test_targets': test_targets,\n",
        "        'model': model\n",
        "    }\n",
        "\n",
        "# Train models with different pooling methods\n",
        "def compare_pooling_methods():\n",
        "    # Get input dimension\n",
        "    sample = dataset[0]\n",
        "    in_channels = sample.x.shape[1]\n",
        "\n",
        "    # Common parameters\n",
        "    hidden_channels = 64\n",
        "    out_channels = 1  # Regression task\n",
        "    lr = 0.001\n",
        "    weight_decay = 5e-4\n",
        "    epochs = 50\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Initialize models with different pooling methods\n",
        "    models = {\n",
        "        'Mean Pooling': GCNWithPooling(in_channels, hidden_channels, out_channels, 'mean').to(device),\n",
        "        'Max Pooling': GCNWithPooling(in_channels, hidden_channels, out_channels, 'max').to(device),\n",
        "        'Sum Pooling': GCNWithPooling(in_channels, hidden_channels, out_channels, 'sum').to(device)\n",
        "    }\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining model with {name}...\")\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        results[name] = train_and_evaluate(model, optimizer, criterion, train_loader, val_loader, test_loader, epochs)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run the comparison\n",
        "pooling_results = compare_pooling_methods()\n",
        "\n",
        "# Visualize training curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training loss\n",
        "plt.subplot(1, 2, 1)\n",
        "for name, result in pooling_results.items():\n",
        "    plt.plot(result['train_losses'], label=f\"{name} (Train)\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Training Loss Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "for name, result in pooling_results.items():\n",
        "    plt.plot(result['val_losses'], label=f\"{name} (Val)\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Validation Loss Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize test performance\n",
        "names = list(pooling_results.keys())\n",
        "test_losses = [result['test_loss'] for result in pooling_results.values()]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(names, test_losses)\n",
        "plt.xlabel('Pooling Method')\n",
        "plt.ylabel('Test Loss (MSE)')\n",
        "plt.title('Test Loss Comparison')\n",
        "\n",
        "# Add value labels on the bars\n",
        "for bar, val in zip(bars, test_losses):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, bar.get_height() + 0.01, f'{val:.4f}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize predictions vs targets for each model\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, (name, result) in enumerate(pooling_results.items()):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.scatter(result['test_targets'].numpy(), result['test_preds'].numpy(), alpha=0.5)\n",
        "    plt.plot([-10, 2], [-10, 2], 'r--')  # Diagonal line for perfect predictions\n",
        "    plt.xlabel('Actual log(Solubility)')\n",
        "    plt.ylabel('Predicted log(Solubility)')\n",
        "    plt.title(f'{name}')\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_DI99KP4FI_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Exploring the Effect of Network Depth\n",
        "\n",
        "Now, let's investigate how the number of GCN layers affects model performance:"
      ],
      "metadata": {
        "id": "I17RC4VFFOGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VariableDepthGCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
        "        super(VariableDepthGCN, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Input layer\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "\n",
        "        # Hidden layers\n",
        "        self.convs = nn.ModuleList([GCNConv(hidden_channels, hidden_channels) for _ in range(num_layers - 1)])\n",
        "\n",
        "        # Output layers\n",
        "        self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # First GCN layer\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        # Additional GCN layers\n",
        "        for i in range(self.num_layers - 1):\n",
        "            x = F.relu(self.convs[i](x, edge_index))\n",
        "\n",
        "        # Global pooling\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        # MLP for final prediction\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def visualize_receptive_field(num_layers):\n",
        "    \"\"\"Visualize how the receptive field grows with network depth\"\"\"\n",
        "    # Create a simple grid graph for visualization\n",
        "    G = nx.grid_2d_graph(5, 5)\n",
        "\n",
        "    # Convert to 0-indexed integer nodes\n",
        "    G = nx.convert_node_labels_to_integers(G)\n",
        "\n",
        "    # Set positions\n",
        "    pos = {i: (i % 5, i // 5) for i in range(25)}\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(1, num_layers + 1, figsize=(4 * (num_layers + 1), 4))\n",
        "\n",
        "    # Central node\n",
        "    central_node = 12  # Middle of the grid\n",
        "\n",
        "    # Drawing the initial graph with the central node highlighted\n",
        "    ax = axes[0]\n",
        "    nodes = nx.draw_networkx_nodes(G, pos, node_color=['red' if n == central_node else 'lightblue' for n in G.nodes()],\n",
        "                                 node_size=500, ax=ax)\n",
        "    edges = nx.draw_networkx_edges(G, pos, ax=ax)\n",
        "    labels = nx.draw_networkx_labels(G, pos, ax=ax)\n",
        "    ax.set_title(\"Initial Node\")\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Draw receptive field for each layer\n",
        "    for layer in range(1, num_layers + 1):\n",
        "        ax = axes[layer]\n",
        "\n",
        "        # Compute nodes in the receptive field after 'layer' hops\n",
        "        receptive_field = {central_node}\n",
        "        current_boundary = {central_node}\n",
        "\n",
        "        for _ in range(layer):\n",
        "            new_boundary = set()\n",
        "            for node in current_boundary:\n",
        "                new_boundary.update(G.neighbors(node))\n",
        "            receptive_field.update(new_boundary)\n",
        "            current_boundary = new_boundary\n",
        "\n",
        "        # Color nodes based on whether they're in the receptive field\n",
        "        node_colors = ['red' if n == central_node else\n",
        "                      'orange' if n in receptive_field and n != central_node else\n",
        "                      'lightblue' for n in G.nodes()]\n",
        "\n",
        "        nodes = nx.draw_networkx_nodes(G, pos, node_color=node_colors,\n",
        "                                     node_size=500, ax=ax)\n",
        "        edges = nx.draw_networkx_edges(G, pos, ax=ax)\n",
        "        labels = nx.draw_networkx_labels(G, pos, ax=ax)\n",
        "        ax.set_title(f\"After {layer} GCN Layers\")\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize how the receptive field grows with depth\n",
        "visualize_receptive_field(num_layers=3)\n",
        "\n",
        "# Compare models with different depths\n",
        "def compare_network_depths():\n",
        "    # Get input dimension\n",
        "    sample = dataset[0]\n",
        "    in_channels = sample.x.shape[1]\n",
        "\n",
        "    # Common parameters\n",
        "    hidden_channels = 64\n",
        "    out_channels = 1  # Regression task\n",
        "    lr = 0.001\n",
        "    weight_decay = 5e-4\n",
        "    epochs = 50\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Initialize models with different depths\n",
        "    models = {\n",
        "        '1 Layer': VariableDepthGCN(in_channels, hidden_channels, out_channels, num_layers=1).to(device),\n",
        "        '2 Layers': VariableDepthGCN(in_channels, hidden_channels, out_channels, num_layers=2).to(device),\n",
        "        '3 Layers': VariableDepthGCN(in_channels, hidden_channels, out_channels, num_layers=3).to(device),\n",
        "        '4 Layers': VariableDepthGCN(in_channels, hidden_channels, out_channels, num_layers=4).to(device),\n",
        "        '5 Layers': VariableDepthGCN(in_channels, hidden_channels, out_channels, num_layers=5).to(device),\n",
        "    }\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining model with {name}...\")\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        results[name] = train_and_evaluate(model, optimizer, criterion, train_loader, val_loader, test_loader, epochs)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run the comparison\n",
        "depth_results = compare_network_depths()\n",
        "\n",
        "# Visualize training curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training loss\n",
        "plt.subplot(1, 2, 1)\n",
        "for name, result in depth_results.items():\n",
        "    plt.plot(result['train_losses'], label=f\"{name} (Train)\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Training Loss vs. Network Depth')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "for name, result in depth_results.items():\n",
        "    plt.plot(result['val_losses'], label=f\"{name} (Val)\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Validation Loss vs. Network Depth')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize test performance\n",
        "names = list(depth_results.keys())\n",
        "test_losses = [result['test_loss'] for result in depth_results.values()]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(names, test_losses)\n",
        "plt.xlabel('Number of GCN Layers')\n",
        "plt.ylabel('Test Loss (MSE)')\n",
        "plt.title('Test Loss vs. Network Depth')\n",
        "\n",
        "# Add value labels on the bars\n",
        "for bar, val in zip(bars, test_losses):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, bar.get_height() + 0.01, f'{val:.4f}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create a visual explanation of the oversmoothing problem\n",
        "def visualize_oversmoothing()\n",
        "\n",
        "# Explain the oversmoothing problem\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.text(0.1, 0.5)"
      ],
      "metadata": {
        "id": "vrSPTQFFFP1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Oversmoothing Problem in Deep GCNs\n",
        "\n",
        "As more GCN layers are added, node features tend to converge to similar values, causing:\n",
        "\n",
        "1. **Loss of Discriminative Power**: Nodes become indistinguishable\n",
        "2. **Gradient Vanishing**: Training becomes more difficult\n",
        "3. **Decreased Performance**: Model accuracy drops after certain depth\n",
        "\n",
        "This phenomenon, called \"oversmoothing,\" explains why GCNs often don't benefit\n",
        "from extra depth like CNNs or Transformers.\n",
        "\n",
        "# Solutions for Oversmoothing:\n",
        "\n",
        "1. **Skip Connections**: Allow information to flow directly from earlier layers\n",
        "2. **Normalization Techniques**: Layer norm, batch norm, etc.\n",
        "3. **Residual Connections**: Help preserve feature diversity\n",
        "4. **Attention Mechanisms**: Focus on important neighbors (like GAT)\n",
        "\n",
        "Next, let's investigate how skip connections can mitigate the oversmoothing problem\n",
        "\n",
        "## 7. Understanding and Implementing Skip Connections\n",
        "\n",
        "Skip (or residual) connections allow information to flow directly from earlier layers to later layers, bypassing intermediate operations. Let's explore how they can improve GCN performance:"
      ],
      "metadata": {
        "id": "-QuGDIjfG7CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNWithSkipConnections(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, use_skip=True):\n",
        "        super(GCNWithSkipConnections, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.use_skip = use_skip\n",
        "\n",
        "        # Input layer\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "\n",
        "        # Hidden layers\n",
        "        self.convs = nn.ModuleList([GCNConv(hidden_channels, hidden_channels) for _ in range(num_layers - 1)])\n",
        "\n",
        "        # Output layers\n",
        "        self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # First GCN layer\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        # Additional GCN layers with potential skip connections\n",
        "        for i in range(self.num_layers - 1):\n",
        "            if self.use_skip:\n",
        "                # Store the input to this layer\n",
        "                identity = x\n",
        "                # Apply GCN and activation\n",
        "                x = F.relu(self.convs[i](x, edge_index))\n",
        "                # Add skip connection (residual)\n",
        "                x = x + identity\n",
        "            else:\n",
        "                # Standard GCN without skip\n",
        "                x = F.relu(self.convs[i](x, edge_index))\n",
        "\n",
        "        # Global pooling\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        # MLP for final prediction\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def visualize_skip_connections():\n",
        "    \"\"\"Create a visual explanation of how skip connections work\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    # Regular GCN Layers\n",
        "    offset = 0\n",
        "    rect_width = 1.5\n",
        "    rect_height = 3\n",
        "    spacing = 2.5\n",
        "\n",
        "    # Draw boxes for standard GCN\n",
        "    y_pos = 2.5\n",
        "    for i in range(4):\n",
        "        rect = plt.Rectangle((offset + i*spacing, y_pos), rect_width, rect_height,\n",
        "                            facecolor='lightblue', edgecolor='black', alpha=0.7)\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(offset + i*spacing + rect_width/2, y_pos + rect_height/2, f\"Layer {i+1}\",\n",
        "              ha='center', va='center', fontsize=10)\n",
        "\n",
        "    # Draw arrows connecting layers\n",
        "    for i in range(3):\n",
        "        ax.arrow(offset + i*spacing + rect_width, y_pos + rect_height/2,\n",
        "               spacing - rect_width, 0, head_width=0.2, head_length=0.3,\n",
        "               fc='black', ec='black')\n",
        "\n",
        "    # Label for standard GCN\n",
        "    ax.text(offset + 1.5*spacing, y_pos + rect_height + 0.5, \"Standard GCN\",\n",
        "          ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "    # Draw boxes for GCN with skip connections\n",
        "    y_pos = -2.5\n",
        "    for i in range(4):\n",
        "        rect = plt.Rectangle((offset + i*spacing, y_pos), rect_width, rect_height,\n",
        "                            facecolor='lightgreen', edgecolor='black', alpha=0.7)\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(offset + i*spacing + rect_width/2, y_pos + rect_height/2, f\"Layer {i+1}\",\n",
        "              ha='center', va='center', fontsize=10)\n",
        "\n",
        "    # Draw regular arrows connecting layers\n",
        "    for i in range(3):\n",
        "        ax.arrow(offset + i*spacing + rect_width, y_pos + rect_height/2,\n",
        "               spacing - rect_width, 0, head_width=0.2, head_length=0.3,\n",
        "               fc='black', ec='black')\n",
        "\n",
        "    # Draw skip connection arrows\n",
        "    for i in range(2):\n",
        "        ax.arrow(offset + i*spacing + rect_width/2, y_pos + rect_height,\n",
        "               spacing, 0, head_width=0.2, head_length=0.3,\n",
        "               fc='red', ec='red', linestyle='--')\n",
        "\n",
        "    # Label for GCN with skip connections\n",
        "    ax.text(offset + 1.5*spacing, y_pos - 0.5, \"GCN with Skip Connections\",\n",
        "          ha='center', va='top', fontsize=12)\n",
        "\n",
        "    # Add explanatory labels\n",
        "    ax.text(offset + 1*spacing + rect_width/2, y_pos + rect_height + 1.5,\n",
        "          \"Skip connections allow information to\\nbypass intermediate layers\",\n",
        "          ha='center', va='center', fontsize=10)\n",
        "\n",
        "    ax.text(offset + 2*spacing + rect_width/2, 0,\n",
        "          \"Benefits:\\n- Mitigates oversmoothing\\n- Improves gradient flow\\n- Enables deeper architectures\",\n",
        "          ha='center', va='center', fontsize=10, bbox=dict(facecolor='white', alpha=0.7))\n",
        "\n",
        "    ax.set_xlim(-0.5, 10)\n",
        "    ax.set_ylim(-4, 7)\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize skip connections\n",
        "visualize_skip_connections()\n",
        "\n",
        "# Compare models with and without skip connections at different depths\n",
        "def compare_skip_connections():\n",
        "    # Get input dimension\n",
        "    sample = dataset[0]\n",
        "    in_channels = sample.x.shape[1]\n",
        "\n",
        "    # Common parameters\n",
        "    hidden_channels = 64\n",
        "    out_channels = 1  # Regression task\n",
        "    lr = 0.001\n",
        "    weight_decay = 5e-4\n",
        "    epochs = 50\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Initialize models with different depths and skip connection settings\n",
        "    models = {\n",
        "        '2 Layers (No Skip)': GCNWithSkipConnections(in_channels, hidden_channels, out_channels, num_layers=2, use_skip=False).to(device),\n",
        "        '2 Layers (With Skip)': GCNWithSkipConnections(in_channels, hidden_channels, out_channels, num_layers=2, use_skip=True).to(device),\n",
        "        '4 Layers (No Skip)': GCNWithSkipConnections(in_channels, hidden_channels, out_channels, num_layers=4, use_skip=False).to(device),\n",
        "        '4 Layers (With Skip)': GCNWithSkipConnections(in_channels, hidden_channels, out_channels, num_layers=4, use_skip=True).to(device),\n",
        "        '6 Layers (No Skip)': GCNWithSkipConnections(in_channels, hidden_channels, out_channels, num_layers=6, use_skip=False).to(device),\n",
        "        '6 Layers (With Skip)': GCNWithSkipConnections(in_channels, hidden_channels, out_channels, num_layers=6, use_skip=True).to(device),\n",
        "    }\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining model: {name}...\")\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        results[name] = train_and_evaluate(model, optimizer, criterion, train_loader, val_loader, test_loader, epochs)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run the comparison\n",
        "skip_results = compare_skip_connections()\n",
        "\n",
        "# Visualize training curves\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot training loss\n",
        "plt.subplot(1, 2, 1)\n",
        "colors = ['blue', 'orange', 'green']\n",
        "linestyles = ['-', '--']\n",
        "\n",
        "for i, depth in enumerate([2, 4, 6]):\n",
        "    for j, skip in enumerate([False, True]):\n",
        "        name = f\"{depth} Layers ({'With' if skip else 'No'} Skip)\"\n",
        "        result = skip_results[name]\n",
        "        plt.plot(result['train_losses'], color=colors[i], linestyle=linestyles[j],\n",
        "                label=name)\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Training Loss: Skip Connections vs. Network Depth')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "for i, depth in enumerate([2, 4, 6]):\n",
        "    for j, skip in enumerate([False, True]):\n",
        "        name = f\"{depth} Layers ({'With' if skip else 'No'} Skip)\"\n",
        "        result = skip_results[name]\n",
        "        plt.plot(result['val_losses'], color=colors[i], linestyle=linestyles[j],\n",
        "                label=name)\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Validation Loss: Skip Connections vs. Network Depth')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize test performance\n",
        "names = list(skip_results.keys())\n",
        "test_losses = [result['test_loss'] for result in skip_results.values()]\n",
        "\n",
        "# Group data for better visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Extract data in structured form\n",
        "depths = [2, 4, 6]\n",
        "no_skip_losses = [skip_results[f\"{d} Layers (No Skip)\"][\"test_loss\"] for d in depths]\n",
        "with_skip_losses = [skip_results[f\"{d} Layers (With Skip)\"][\"test_loss\"] for d in depths]\n",
        "\n",
        "# Set up bar positions\n",
        "bar_width = 0.35\n",
        "x = np.arange(len(depths))\n",
        "\n",
        "# Create grouped bars\n",
        "plt.bar(x - bar_width/2, no_skip_losses, bar_width, label='No Skip Connections', color='lightcoral')\n",
        "plt.bar(x + bar_width/2, with_skip_losses, bar_width, label='With Skip Connections', color='lightgreen')\n",
        "\n",
        "# Add labels and customize\n",
        "plt.xlabel('Number of Layers')\n",
        "plt.ylabel('Test Loss (MSE)')\n",
        "plt.title('Effect of Skip Connections at Different Network Depths')\n",
        "plt.xticks(x, depths)\n",
        "plt.legend()\n",
        "plt.grid(True, axis='y')\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(no_skip_losses):\n",
        "    plt.text(i - bar_width/2, v + 0.005, f'{v:.4f}', ha='center', va='bottom', fontsize=9)\n",
        "for i, v in enumerate(with_skip_losses):\n",
        "    plt.text(i + bar_width/2, v + 0.005, f'{v:.4f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze the performance improvement from skip connections\n",
        "improvement = [(no_skip - with_skip) / no_skip * 100 for no_skip, with_skip in zip(no_skip_losses, with_skip_losses)]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(depths, improvement, color='lightblue')\n",
        "plt.xlabel('Number of Layers')\n",
        "plt.ylabel('Improvement (%)')\n",
        "plt.title('Performance Improvement from Skip Connections')\n",
        "plt.grid(True, axis='y')\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(improvement):\n",
        "    plt.text(depths[i], v + 0.5, f'{v:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2VFh6smOG7aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Visualizing Node Feature Learning\n",
        "\n",
        "Let's now visualize how node features evolve through the GCN layers, with and without skip connections:"
      ],
      "metadata": {
        "id": "V9kjQeKqHCt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_feature_evolution(model, data, smiles, use_skip=False):\n",
        "    \"\"\"Visualize how node features are transformed through the GCN layers\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Create hooks to get intermediate activations\n",
        "    activations = {}\n",
        "\n",
        "    def get_activation(name):\n",
        "        def hook(module, input, output):\n",
        "            activations[name] = output.detach()\n",
        "        return hook\n",
        "\n",
        "    # Register hooks for each layer\n",
        "    hooks = []\n",
        "    hooks.append(model.conv1.register_forward_hook(get_activation('conv1')))\n",
        "    for i, conv in enumerate(model.convs):\n",
        "        hooks.append(conv.register_forward_hook(get_activation(f'conv{i+2}')))\n",
        "\n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        # Move data to the correct device\n",
        "        data = data.to(device)\n",
        "\n",
        "        # Create a fake batch index (all zeros since we have only one graph)\n",
        "        batch = torch.zeros(data.x.size(0), dtype=torch.long, device=device)\n",
        "\n",
        "        # Forward pass\n",
        "        _ = model(data.x, data.edge_index, batch)\n",
        "\n",
        "    # Remove the hooks\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "\n",
        "    # Get the input features\n",
        "    input_features = data.x.cpu().numpy()\n",
        "\n",
        "    # Get activations for each layer\n",
        "    all_features = [input_features]\n",
        "    for i in range(len(activations)):\n",
        "        all_features.append(activations[f'conv{i+1}'].cpu().numpy())\n",
        "\n",
        "    # Use t-SNE to visualize high-dimensional features\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "\n",
        "    # Create molecule for reference\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    atom_symbols = [atom.GetSymbol() for atom in mol.GetAtoms()]\n",
        "\n",
        "    # Determine how many layers to plot\n",
        "    num_layers = min(4, len(all_features))\n",
        "\n",
        "    # Plot the feature evolution\n",
        "    fig, axes = plt.subplots(1, num_layers, figsize=(4 * num_layers, 4))\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        ax = axes[i]\n",
        "\n",
        "        # Apply t-SNE to reduce dimensions\n",
        "        if all_features[i].shape[1] > 2:\n",
        "            features_2d = tsne.fit_transform(all_features[i])\n",
        "        else:\n",
        "            features_2d = all_features[i]\n",
        "\n",
        "        # Plot the features\n",
        "        scatter = ax.scatter(features_2d[:, 0], features_2d[:, 1], s=100, alpha=0.8)\n",
        "\n",
        "        # Add atom labels\n",
        "        for j, symbol in enumerate(atom_symbols):\n",
        "            ax.text(features_2d[j, 0], features_2d[j, 1], symbol, ha='center', va='center')\n",
        "\n",
        "        # Set title\n",
        "        if i == 0:\n",
        "            ax.set_title('Input Features')\n",
        "        else:\n",
        "            ax.set_title(f'After Layer {i}')\n",
        "\n",
        "        ax.set_xlabel('t-SNE Dimension 1')\n",
        "        ax.set_ylabel('t-SNE Dimension 2')\n",
        "\n",
        "    plt.suptitle(f'Feature Evolution in GCN {\"with\" if use_skip else \"without\"} Skip Connections', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return all_features\n",
        "\n",
        "# Create and train two small models for visualization\n",
        "def train_small_model_for_vis(use_skip=False):\n",
        "    \"\"\"Train a small model for feature visualization\"\"\"\n",
        "    # Get sample molecule\n",
        "    smiles = example_molecules[\"Aspirin\"]\n",
        "    data = mol_to_graph(smiles)\n",
        "\n",
        "    # Create model\n",
        "    in_channels = data.x.shape[1]\n",
        "    hidden_channels = 16\n",
        "    out_channels = 1\n",
        "    num_layers = 4\n",
        "\n",
        "    model = GCNWithSkipConnections(\n",
        "        in_channels,\n",
        "        hidden_channels,\n",
        "        out_channels,\n",
        "        num_layers=num_layers,\n",
        "        use_skip=use_skip\n",
        "    ).to(device)\n",
        "\n",
        "    # Train briefly (just to get some reasonable parameters)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Fake target\n",
        "    target = torch.Tensor([0.5]).to(device)\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(50):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x.to(device), data.edge_index.to(device), torch.zeros(data.x.size(0), dtype=torch.long, device=device))\n",
        "        loss = criterion(out, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return model, data, smiles\n",
        "\n",
        "# Get models\n",
        "no_skip_model, aspirin_data, aspirin_smiles = train_small_model_for_vis(use_skip=False)\n",
        "skip_model, _, _ = train_small_model_for_vis(use_skip=True)\n",
        "\n",
        "# Visualize feature evolution\n",
        "no_skip_features = visualize_feature_evolution(no_skip_model, aspirin_data, aspirin_smiles, use_skip=False)\n",
        "skip_features = visualize_feature_evolution(skip_model, aspirin_data, aspirin_smiles, use_skip=True)\n",
        "\n",
        "# Calculate feature diversity through layers\n",
        "def feature_diversity(features_list):\n",
        "    \"\"\"Calculate how diverse the features are at each layer\"\"\"\n",
        "    return [np.var(features, axis=0).mean() for features in features_list]\n",
        "\n",
        "no_skip_diversity = feature_diversity(no_skip_features)\n",
        "skip_diversity = feature_diversity(skip_features)\n",
        "\n",
        "# Plot feature diversity\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(len(no_skip_diversity)), no_skip_diversity, 'o-', label='Without Skip Connections')\n",
        "plt.plot(range(len(skip_diversity)), skip_diversity, 's-', label='With Skip Connections')\n",
        "plt.xlabel('Layer')\n",
        "plt.ylabel('Feature Diversity (Variance)')\n",
        "plt.title('Feature Diversity Through GCN Layers')\n",
        "plt.xticks(range(len(no_skip_diversity)))\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TxR42aELHE6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Practical Application: Molecular Property Prediction\n",
        "\n",
        "Let's apply what we've learned to a practical task: predicting molecular properties."
      ],
      "metadata": {
        "id": "HUNpQAuvHI32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MolecularGCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=64, out_channels=1, num_layers=3,\n",
        "                 use_skip=True, pooling='mean'):\n",
        "        super(MolecularGCN, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.use_skip = use_skip\n",
        "        self.pooling = pooling\n",
        "\n",
        "        # Input layer\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "\n",
        "        # Hidden layers\n",
        "        self.convs = nn.ModuleList([GCNConv(hidden_channels, hidden_channels) for _ in range(num_layers - 1)])\n",
        "\n",
        "        # Batch normalization layers\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_channels) for _ in range(num_layers)])\n",
        "\n",
        "        # Output layers\n",
        "        self.lin1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.lin2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # First GCN layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bns[0](x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Additional GCN layers with potential skip connections\n",
        "        prev_x = x\n",
        "\n",
        "        for i in range(self.num_layers - 1):\n",
        "            # Apply GCN\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = self.bns[i+1](x)\n",
        "\n",
        "            # Apply skip connection if specified\n",
        "            if self.use_skip:\n",
        "                x = x + prev_x\n",
        "\n",
        "            x = F.relu(x)\n",
        "            prev_x = x\n",
        "\n",
        "        # Global pooling based on specified method\n",
        "        if self.pooling == 'max':\n",
        "            x = global_max_pool(x, batch)\n",
        "        elif self.pooling == 'sum':\n",
        "            x = global_add_pool(x, batch)\n",
        "        else:  # Default to mean\n",
        "            x = global_mean_pool(x, batch)\n",
        "\n",
        "        # Final prediction\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Train the optimized model and evaluate it\n",
        "# Use hyperparameters from our experiments\n",
        "def train_optimized_model():\n",
        "    # Get input dimension\n",
        "    sample = dataset[0]\n",
        "    in_channels = sample.x.shape[1]\n",
        "\n",
        "    # Based on our findings, use the best configuration\n",
        "    model = MolecularGCN(\n",
        "        in_channels=in_channels,\n",
        "        hidden_channels=64,\n",
        "        out_channels=1,\n",
        "        num_layers=4,  # Moderate depth\n",
        "        use_skip=True,  # Use skip connections\n",
        "        pooling='mean'  # Found to work best for this task\n",
        "    ).to(device)\n",
        "\n",
        "    # Set up optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Training optimized model...\")\n",
        "    results = train_and_evaluate(model, optimizer, criterion, train_loader, val_loader, test_loader, epochs=50)\n",
        "\n",
        "    return model, results\n",
        "\n",
        "# Train and evaluate the optimized model\n",
        "optimized_model, optimized_results = train_optimized_model()\n",
        "\n",
        "# Plot final predictions vs targets\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(optimized_results['test_targets'].numpy(),\n",
        "           optimized_results['test_preds'].numpy(),\n",
        "           alpha=0.7)\n",
        "plt.plot([-10, 2], [-10, 2], 'r--')  # Perfect prediction line\n",
        "plt.xlabel('Actual log(Solubility)')\n",
        "plt.ylabel('Predicted log(Solubility)')\n",
        "plt.title('Optimized GCN: Predictions vs Actual Values')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate performance metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "y_true = optimized_results['test_targets'].numpy()\n",
        "y_pred = optimized_results['test_preds'].numpy()\n",
        "\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test R²: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "JFQW8eRdHKwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Molecular Analysis: Understanding What the GCN Learns\n",
        "\n",
        "Now let's analyze the model to gain insights into what it's learning about molecular structures:"
      ],
      "metadata": {
        "id": "M9SZRBy1HPIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_important_substructures(model, test_loader):\n",
        "    \"\"\"Identify and visualize substructures that are important for prediction\"\"\"\n",
        "    # Get a few test molecules\n",
        "    test_mols = []\n",
        "    for i, data in enumerate(test_loader):\n",
        "        if i >= 3:  # Just get a few examples\n",
        "            break\n",
        "        # Get batch data\n",
        "        for j in range(min(3, data.num_graphs)):  # Get up to 3 molecules from batch\n",
        "            if hasattr(data, 'smiles'):\n",
        "                smiles = data.smiles[j]\n",
        "            else:\n",
        "                # If SMILES not available, create a generic identifier\n",
        "                smiles = f\"molecule_{i}_{j}\"\n",
        "\n",
        "            # Extract individual molecule data\n",
        "            mask = data.batch == j\n",
        "            mol_data = Data(\n",
        "                x=data.x[mask],\n",
        "                edge_index=data.edge_index[:, mask[data.edge_index[0]]],\n",
        "                y=data.y[j:j+1]\n",
        "            )\n",
        "            mol_data.smiles = smiles\n",
        "            test_mols.append(mol_data)\n",
        "\n",
        "    # Function to compute node importance for a molecule\n",
        "    def compute_node_importance(model, data):\n",
        "        model.eval()\n",
        "        data = data.to(device)\n",
        "\n",
        "        # Create gradient hook\n",
        "        node_grads = []\n",
        "\n",
        "        def save_grads(grad):\n",
        "            node_grads.append(grad.cpu().detach())\n",
        "\n",
        "        # Move to device and require gradients\n",
        "        x = data.x.to(device)\n",
        "        x.requires_grad_(True)\n",
        "        edge_index = data.edge_index.to(device)\n",
        "        batch = torch.zeros(x.size(0), dtype=torch.long, device=device)\n",
        "\n",
        "        # Register hook for gradients\n",
        "        x.register_hook(save_grads)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(x, edge_index, batch)\n",
        "\n",
        "        # Backward pass\n",
        "        output.backward()\n",
        "\n",
        "        # Get gradients\n",
        "        grads = node_grads[0]\n",
        "\n",
        "        # Compute importance as gradient magnitude\n",
        "        importance = torch.norm(grads, dim=1).numpy()\n",
        "\n",
        "        return importance\n",
        "\n",
        "    # For each test molecule, visualize node importance\n",
        "    for i, mol_data in enumerate(test_mols):\n",
        "        if not hasattr(mol_data, 'smiles') or not mol_data.smiles:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            smiles = mol_data.smiles\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "            if mol is None:\n",
        "                continue\n",
        "\n",
        "            # Compute node importance\n",
        "            importance = compute_node_importance(model, mol_data)\n",
        "\n",
        "            # Normalize importance\n",
        "            importance = (importance - importance.min()) / (importance.max() - importance.min() + 1e-8)\n",
        "\n",
        "            # Create a molecule graph\n",
        "            AllChem.Compute2DCoords(mol)\n",
        "            G = nx.Graph()\n",
        "\n",
        "            # Add nodes and edges\n",
        "            for atom in mol.GetAtoms():\n",
        "                G.add_node(atom.GetIdx())\n",
        "\n",
        "            for bond in mol.GetBonds():\n",
        "                G.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
        "\n",
        "            # Get positions for visualization\n",
        "            pos = {}\n",
        "            for atom in mol.GetAtoms():\n",
        "                pos[atom.GetIdx()] = mol.GetConformer().GetAtomPosition(atom.GetIdx())\n",
        "                pos[atom.GetIdx()] = (pos[atom.GetIdx()].x, -pos[atom.GetIdx()].y)  # Flip y for better visualization\n",
        "\n",
        "            # Get atom labels\n",
        "            atom_labels = {atom.GetIdx(): atom.GetSymbol() for atom in mol.GetAtoms()}\n",
        "\n",
        "            # Create figure\n",
        "            plt.figure(figsize=(12, 5))\n",
        "\n",
        "            # Plot molecule\n",
        "            plt.subplot(1, 2, 1)\n",
        "            drawer = rdMolDraw2D.MolDraw2DCairo(500, 500)\n",
        "            drawer.DrawMolecule(mol)\n",
        "            drawer.FinishDrawing()\n",
        "            img = drawer.GetDrawingText()\n",
        "\n",
        "            # Convert to PIL Image and display\n",
        "            pil_image = Image.open(io.BytesIO(img))\n",
        "            plt.imshow(pil_image)\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Molecule {i+1}\")\n",
        "\n",
        "            # Plot graph with node importance\n",
        "            plt.subplot(1, 2, 2)\n",
        "\n",
        "            # Create a colormap for importance\n",
        "            cmap = plt.cm.viridis\n",
        "            node_colors = [cmap(imp) for imp in importance]\n",
        "\n",
        "            # Draw the graph\n",
        "            nx.draw(G, pos,\n",
        "                   labels=atom_labels,\n",
        "                   with_labels=True,\n",
        "                   node_color=importance,\n",
        "                   cmap=plt.cm.viridis,\n",
        "                   node_size=500,\n",
        "                   font_size=10,\n",
        "                   font_color='white',\n",
        "                   edge_color='gray',\n",
        "                   vmin=0, vmax=1)\n",
        "\n",
        "            # Add a colorbar\n",
        "            sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, norm=plt.Normalize(vmin=0, vmax=1))\n",
        "            sm.set_array([])\n",
        "            cbar = plt.colorbar(sm)\n",
        "            cbar.set_label('Node Importance')\n",
        "\n",
        "            plt.title(f\"Node Importance for Prediction\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # Show actual vs predicted value\n",
        "            pred = model(mol_data.x.to(device), mol_data.edge_index.to(device),\n",
        "                        torch.zeros(mol_data.x.size(0), dtype=torch.long, device=device))\n",
        "            print(f\"Molecule {i+1} - Actual: {mol_data.y.item():.4f}, Predicted: {pred.item():.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing molecule {i+1}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "# Visualize important substructures for a few test molecules\n",
        "visualize_important_substructures(optimized_model, test_loader)"
      ],
      "metadata": {
        "id": "sBLWKDVFHQyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Conclusion and Comprehensive Findings"
      ],
      "metadata": {
        "id": "z_emMuDEHVG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_findings():\n",
        "    \"\"\"Create a visual summary of our findings about GCNs\"\"\"\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    text = \"\"\"\n",
        "    # Graph Convolutional Networks for Molecular Property Prediction\n",
        "\n",
        "    ## Key Findings\n",
        "\n",
        "    ### 1. Effect of Pooling Methods\n",
        "    - **Mean Pooling**: Provides balanced representation, generally performs well for diverse molecules.\n",
        "    - **Max Pooling**: Captures important features but ignores global structure. Good for identifying key substructures.\n",
        "    - **Sum Pooling**: Better for capturing overall molecular properties, but can be sensitive to molecule size.\n",
        "\n",
        "    ### 2. Effect of Network Depth\n",
        "    - **Shallow Networks (1-2 layers)**: Capture local molecular features but miss long-range interactions.\n",
        "    - **Medium Networks (3-4 layers)**: Good balance between local and global features.\n",
        "    - **Deep Networks (5+ layers)**: Suffer from oversmoothing without skip connections.\n",
        "\n",
        "    ### 3. Skip Connections\n",
        "    - More important as network depth increases\n",
        "    - Preserve feature diversity by preventing oversmoothing\n",
        "    - Allow effective information flow in deep networks\n",
        "    - Particularly beneficial for large, complex molecules\n",
        "\n",
        "    ## Best Practices for Molecular GCNs\n",
        "\n",
        "    1. Use skip connections for networks deeper than 2-3 layers\n",
        "    2. Choose pooling method based on the property you're predicting:\n",
        "       - Mean pooling for general properties (e.g., solubility, logP)\n",
        "       - Max pooling for properties dependent on specific substructures\n",
        "       - Sum pooling for properties that scale with molecule size\n",
        "    3. Add batch normalization between GCN layers for better training\n",
        "    4. Moderate depth (3-4 layers) usually provides the best balance\n",
        "\n",
        "    ## Future Directions\n",
        "\n",
        "    1. Explore edge features for better bond representation\n",
        "    2. Combine GCNs with attention mechanisms (like GATs)\n",
        "    3. Incorporate 3D molecular information\n",
        "    4. Use multi-task learning for related molecular properties\n",
        "    \"\"\"\n",
        "    plt.text(0.05, 0.5, text, fontsize=14, fontfamily='monospace',\n",
        "            verticalalignment='center', horizontalalignment='left')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Summarize our findings\n",
        "summarize_findings()"
      ],
      "metadata": {
        "id": "CxqL9wShHXk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Additional Resources and References\n",
        "\n",
        "Here are some important papers and resources for further exploration of GCNs in chemistry:\n",
        "\n",
        "1. **Original GCN paper**: Kipf & Welling, \"Semi-Supervised Classification with Graph Convolutional Networks\" (2017)\n",
        "2. **Chemical GCNs**: Yang et al., \"Analyzing Learned Molecular Representations for Property Prediction\" (2019)\n",
        "3. **Oversmoothing**: Li et al., \"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning\" (2018)\n",
        "4. **Skip Connections**: Xu et al., \"Representation Learning on Graphs with Jumping Knowledge Networks\" (2018)"
      ],
      "metadata": {
        "id": "hTg-ys8BHbLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_resources_visualization():\n",
        "    \"\"\"Create a visual guide to GCN resources\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Create a mind map style visualization\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Add nodes for different categories\n",
        "    G.add_node(\"GCNs in Chemistry\", pos=(0, 0))\n",
        "\n",
        "    # Add resource categories\n",
        "    categories = [\"Foundational Papers\", \"Applications\", \"Advanced Architectures\", \"Software Tools\"]\n",
        "    for i, category in enumerate(categories):\n",
        "        angle = 2 * np.pi * i / len(categories)\n",
        "        x = 3 * np.cos(angle)\n",
        "        y = 3 * np.sin(angle)\n",
        "        G.add_node(category, pos=(x, y))\n",
        "        G.add_edge(\"GCNs in Chemistry\", category)\n",
        "\n",
        "    # Add specific resources for each category\n",
        "    resources = {\n",
        "        \"Foundational Papers\": [\n",
        "            \"Kipf & Welling (2017)\\nGCN\",\n",
        "            \"Hamilton et al. (2017)\\nGraphSAGE\",\n",
        "            \"Li et al. (2018)\\nGCN Oversmoothing\"\n",
        "        ],\n",
        "        \"Applications\": [\n",
        "            \"Drug Discovery\",\n",
        "            \"QSAR Modeling\",\n",
        "            \"Reaction Prediction\",\n",
        "            \"Retrosynthesis\"\n",
        "        ],\n",
        "        \"Advanced Architectures\": [\n",
        "            \"GAT\",\n",
        "            \"GIN\",\n",
        "            \"SchNet (3D)\",\n",
        "            \"DimeNet++\"\n",
        "        ],\n",
        "        \"Software Tools\": [\n",
        "            \"PyTorch Geometric\",\n",
        "            \"DGL\",\n",
        "            \"RDKit\",\n",
        "            \"DeepChem\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Add resource nodes\n",
        "    for category, res_list in resources.items():\n",
        "        cat_idx = categories.index(category)\n",
        "        cat_angle = 2 * np.pi * cat_idx / len(categories)\n",
        "        cat_x = 3 * np.cos(cat_angle)\n",
        "        cat_y = 3 * np.sin(cat_angle)\n",
        "\n",
        "        for i, resource in enumerate(res_list):\n",
        "            # Calculate position in a small arc around the category\n",
        "            angle_offset = (i - (len(res_list) - 1) / 2) * 0.2\n",
        "            dist = 2.5\n",
        "            x = cat_x + dist * np.cos(cat_angle + angle_offset)\n",
        "            y = cat_y + dist * np.sin(cat_angle + angle_offset)\n",
        "            G.add_node(resource, pos=(x, y))\n",
        "            G.add_edge(category, resource)\n",
        "\n",
        "    # Get positions\n",
        "    pos = nx.get_node_attributes(G, 'pos')\n",
        "\n",
        "    # Draw the graph\n",
        "    nx.draw_networkx_nodes(G, pos,\n",
        "                         nodelist=[\"GCNs in Chemistry\"],\n",
        "                         node_size=5000,\n",
        "                         node_color='lightblue',\n",
        "                         alpha=0.8)\n",
        "\n",
        "    nx.draw_networkx_nodes(G, pos,\n",
        "                         nodelist=categories,\n",
        "                         node_size=3000,\n",
        "                         node_color='lightgreen',\n",
        "                         alpha=0.8)\n",
        "\n",
        "    # Create a flattened list of all resources\n",
        "    all_resources = [res for res_list in resources.values() for res in res_list]\n",
        "\n",
        "    nx.draw_networkx_nodes(G, pos,\n",
        "                         nodelist=all_resources,\n",
        "                         node_size=2000,\n",
        "                         node_color='lightsalmon',\n",
        "                         alpha=0.8)\n",
        "\n",
        "    # Draw edges\n",
        "    nx.draw_networkx_edges(G, pos, width=1.5, alpha=0.5)\n",
        "\n",
        "    # Draw labels\n",
        "    nx.draw_networkx_labels(G, pos,\n",
        "                          font_size=10,\n",
        "                          font_family='sans-serif')\n",
        "\n",
        "    plt.title(\"Resources for Graph Convolutional Networks in Chemistry\", fontsize=16)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Show resources\n",
        "create_resources_visualization()\n",
        "\n",
        "print(\"This concludes our tutorial on Graph Convolutional Networks for molecular property prediction!\")"
      ],
      "metadata": {
        "id": "B-Mc-KgAHdP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This completes our comprehensive tutorial on Graph Convolutional Networks for chemists and pharmacists, with special focus on pooling methods, network depth, and skip connections."
      ],
      "metadata": {
        "id": "TcKT1HBHHrK8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jN-KedJfHsEN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}